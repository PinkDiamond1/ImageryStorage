{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, importlib, zipfile\n",
    "import rasterio, geohash\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Get reference to imagery object\n",
    "sys.path.append('../src')\n",
    "\n",
    "from ImageryObjects import imageryExtents\n",
    "\n",
    "globalBoundaries = r\"R:\\GLOBAL\\ADMIN\\Official Bank Borders\\Polygons\\Admin0\\Admin0_Polys.shp\"\n",
    "globalBoundaries = gpd.read_file(globalBoundaries)\n",
    "globalBoundaries = globalBoundaries.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Imagery Metadata\n",
    "This script is designed to extract metadata from our imagery repositories. How the information is to be processed is yet to be determined, but we need to extract the following metadata\n",
    "\n",
    "### Metadata extracted from imagery\n",
    "1. Title\n",
    "2. Country ISO3\n",
    "3. Storage location\n",
    "4. Size zipped\n",
    "5. Resolution\n",
    "6. Number of bands\n",
    "\n",
    "### Metadata extracted from deliverable\n",
    "1. Vendor\n",
    "2. Sensor\n",
    "3. Data of Capture\n",
    "\n",
    "### Manually entered information\n",
    "1. WB project number\n",
    "2. Security classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate information to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFolder =    r\"S:\\COUNTRY\\TJK\\IMAGERY\"# The folder of imagery to process\n",
    "\n",
    "# These two should not be changed - if you do not have access to the I drive, contact Robert Mansour\n",
    "outFolder =       r\"I:\\ddhfiles\\internal\\imagerysource\\Ingest\"\n",
    "processedFolder = r\"I:\\ddhfiles\\internal\\imagerysource\\Processed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating lists of zipFiles and tif files\n",
    "zipFiles = []\n",
    "imgFolders = []\n",
    "for root, dirs, files in os.walk(sourceFolder):\n",
    "    for f in files:\n",
    "        if f[-4:] in [\".zip\", \".rar\"]:\n",
    "            zipFiles.append(os.path.join(root, f))\n",
    "        if f[-4:] in [\".tif\", \".TIF\"]:\n",
    "            process=True\n",
    "            for x in ['spfeas', 'MappyFeatures', 'Spatial_features', 'LandScan_2012']:\n",
    "                if x in root:\n",
    "                    process = False\n",
    "                if process and not root in imgFolders:\n",
    "                    imgFolders.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(zipFiles))\n",
    "print(len(imgFolders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing new folder of imagery\n",
    "importlib.reload(imageryExtents)\n",
    "\n",
    "badData = []\n",
    "errorData = []\n",
    "newFolders = []\n",
    "processedFolders = []\n",
    "\n",
    "#imgFolders = [r\"R:\\Imagery\\DRC\\DRC Tasking (8242019)\\010740474010_01\\010740474010_01_P001_MUL\"]\n",
    "for inFolder in imgFolders:\n",
    "    try:\n",
    "        imgObj = imageryExtents.deliveredImageryFolder(inFolder, outFolder, globalBoundaries, \"\") \n",
    "        #Check if this imgObj has already been processed\n",
    "        processedFile = os.path.join(processedFolder, os.path.basename(imgObj.jsonFile))\n",
    "        if not os.path.exists(processedFile) and not os.path.exists(imgObj.jsonFile):\n",
    "            metaData = imgObj.getMetadata()\n",
    "            if imgObj.valid_metadata(metaData):\n",
    "                thumbnail = imgObj.generateThumbnails()\n",
    "                zipFile = imgObj.zipData()\n",
    "                imgJSON = imgObj.createJSON(pNumber=\"NA\", securityClassification=\"Official Use Only\")\n",
    "            else:\n",
    "                badData.append(metaData)\n",
    "            newFolders.append(inFolder)            \n",
    "        else:\n",
    "            processedFolders.append(inFolder)\n",
    "    except:\n",
    "        errorData.append(inFolder)\n",
    "    print(inFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imgFolders))\n",
    "print(len(badData))\n",
    "print(len(errorData))\n",
    "print(len(newFolders))\n",
    "print(len(processedFolders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do with error data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.wkt import loads\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For these broken SPOT files, run the following command in arcpy - for some reason\n",
    "#  The actual .tif files are not spatially referenced\n",
    "original_location = r'S:\\COUNTRY\\TJK\\IMAGERY\\3020003_HEIN_01800_071401_Tajik_Hazard_SO17014201-8-01_DS_SPOT6_201310200533280_FR1_FR1_SE1_SE1_E073N38_01952\\PROD_SPOT6_001\\VOL_SPOT6_001_A\\IMG_SPOT6_MS_001_A\\DIM_SPOT6_MS_201310200533280_SEN_2406078101.XML'\n",
    "xx = arcpy.Raster(original_location)\n",
    "print(xx.extent.polygon.WKT)\n",
    "print(xx.bandCount)\n",
    "print(xx.meanCellHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip_file_base = \"I:\\ddhfiles\\internal\\imagerysource\\Ingest\"\n",
    "bbox = \"MULTIPOLYGON (((73.083069374010321 38.361483576899239, 73.529317605137848 38.361483576899239, 73.529317605137848 38.682390625431829, 73.083069374010321 38.682390625431829, 73.083069374010321 38.361483576899239)))\"\n",
    "bbox_shp = loads(bbox)\n",
    "iso3 = \";\".join(list(globalBoundaries[globalBoundaries.intersects(bbox_shp)]['ISO3']))\n",
    "g_hash = geohash.encode(bbox_shp.centroid.y, bbox_shp.centroid.x)\n",
    "band_count = 4\n",
    "resolution = 5\n",
    "vendor = \"SPOT\"\n",
    "date = \"20131020\"\n",
    "filename = f\"{iso3}_{g_hash}_{band_count}_{resolution}_{date}.json\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = {\n",
    "    \"title\":f\"Satellite imagery for {iso3}\",\n",
    "    'iso3':f'{iso3}',\n",
    "    'location':f'{os.path.join(zip_file_base, filename.replace(\".json\",\".zip\"))}',\n",
    "    'zipped_size':563444000,\n",
    "    'resolution':f'{resolution}',\n",
    "    'nBands':f'{band_count}',\n",
    "    'vendor':f'{vendor}',\n",
    "    'capture_date':f'{date}',\n",
    "    'pNumber':'NA',\n",
    "    \"securityClassification\": \"Official Use Only\", \n",
    "    \"ImageExtent\":str(bbox_shp),\n",
    "    'originalLocation':original_location\n",
    "}\n",
    "with open(os.path.join(zip_file_base, filename), 'w') as j:\n",
    "    json.dump(vals, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geog)",
   "language": "python",
   "name": "geog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
